# Cloud Computing: Servicios y aplicaciones.
# P4: Computación Distribuida y Escalable con Hadoop
# Gustavo Rivas Gervilla. gustavofox92@correo.ugr.es

## Ejercicios del guión

### Ejercicio 1

Para la realización de este ejercicio simplemente empleamos el código disponible en el servidor Hadoop. Así con este ejercicio lo que hicimos fue aprender cómo ejecutar un código, con paradigma Map-Reduce en el servidor de prácticas. A continuación se muestran los comandos necesarios para compilar las distintas clases que conforman un programa básico con Map-Reduce (la clase principal donde se configuran distintos aspectos del proceso, el Mapper y el Reducer), generar un *jar* con las clases compiladas que finalmente se le pasa a hadoop para ejecutar el código sobre el *dataset* que especifiquemos y enviando la salida al directorio que también pasamos como parámetro.

```bash
javac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-mapreduce/* -d java_classes Min*
/usr/java/jdk1.7.0_51/bin/jar -cvf stat.jar -C java_classes / .

hadoop jar stat.jar oldapi.Min /tmp/BDCC/datasets/ECBDL14/ECBDL14_10tst.data ./stat/output/
```
La salida de este programa es la que se muestra en el tutorial visto en clase con lo que no se muestra en esta memoria.

### Ejercicio 2 (maximo)

El cambio realizado sobre este código ha sido mínimo con respecto al anterior, sólo es necesario cambiar el código de la clase Reducer para que en lugar de buscar el mínimo de todos los valores que recibe como entrada busque el máximo. Lo que se ha hecho para cada uno de los ejercicios ha sido crear una carpeta con el código necesario, y dentro de esta carpeta crear un nuevo directorio *java_classes* y dentro de este directorio compilar como se ha mostrado en el ejercicio anterior; teniendo en cuenta los nombres de las nuevas clases.

**Salida:**
```bash
1       9.0
```

### Ejercicio 3 (minmax)

Este ejercicio resulta muy sencillo una vez hemos realizado los dos anteriores. Simplemente necesitamos unir el código de ambas clases Reducer y añadir a la salida del Reducer dos pares clave-valor, uno para el máximo y otro para el mínimo, realizando dos llamandas al método `collect`. Señalar que si intentamos pasarle como primer parámetros un `String` directamente a este método nos dará un error puesto que lo que espera es un objeto de la clase `Text`.

En esta ocasión adjuntamos además la información del proceso de Map-Reduce que nos da el servidor tras la ejecución del código ya que lo usaremos para comparar tiempo al ejecutar el mismo código sobre un *dataset* más pequeño:

```bash
17/05/19 22:32:38 INFO mapreduce.Job: Counters: 50
        File System Counters
                FILE: Number of bytes read=2173029
                FILE: Number of bytes written=6530753
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=102749934
                HDFS: Number of bytes written=18
                HDFS: Number of read operations=54
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=32
        Job Counters
                Launched map tasks=2
                Launched reduce tasks=16
                Data-local map tasks=1
                Rack-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=108157
                Total time spent by all reduces in occupied slots (ms)=1965292
                Total time spent by all map tasks (ms)=15451
                Total time spent by all reduce tasks (ms)=40108
                Total vcore-seconds taken by all map tasks=15451
                Total vcore-seconds taken by all reduce tasks=40108
                Total megabyte-seconds taken by all map tasks=108157000
                Total megabyte-seconds taken by all reduce tasks=2005400000
        Map-Reduce Framework
                Map input records=2897917
                Map output records=2897917
                Map output bytes=28979170
                Map output materialized bytes=2173056
                Input split bytes=234
                Combine input records=0
                Combine output records=0
                Reduce input groups=1
                Reduce shuffle bytes=2173056
                Reduce input records=2897917
                Reduce output records=2
                Spilled Records=5795834
                Shuffled Maps =32
                Failed Shuffles=0
                Merged Map outputs=32
                GC time elapsed (ms)=341
                CPU time spent (ms)=35730
                Physical memory (bytes) snapshot=7935692800
                Virtual memory (bytes) snapshot=984106909696
                Total committed heap usage (bytes)=19357761536
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters
                Bytes Read=102749700
        File Output Format Counters
                Bytes Written=18
```

**Salida:**
```bash
Max     9.0
Min     -11.0
```

### Ejercicio 4 (minmaxAll)

En esta ocasión el que cambia algo más es el Mapper con respecto al ejercicio anterior, en esta ocasión, dado que queremos calcular el máximo y el mínimo de cada variable por separado necesitamos lanzar un proceso *Reduce* por cada columna del *dataset*, para ello simplemente enviamos cada dato del dataset desde el *Mapper* con el número de la columna a la que pertenece como etiqueta, de este modo cada columna será tratada por separado por un proceso *reduce* distinto. También, para mejorar la lejibilidad de la salida lo que hacemos es que la etiqueta asociada a cada salida del *Reducer* le agregamos el número de la columna a la que pertenece ese máximo o ese mínimo.

**Salida:**
```bash
Max1	0.154
Min1	0.0
Max2	10.0
Min2	-12.0
Max3	8.0
Min3	-11.0
Max4	9.0
Min4	-12.0
Max5	9.0
Min5	-11.0
Max6	9.0
Min6	-13.0
Max7	9.0
Min7	-12.0
Max8	7.0
Min8	-12.0
Max9	10.0
Min9	-13.0
Max0	0.768
Min0	0.094
```
Podemos observar cómo, en el caso de la columna 5, la salida obtenida es la misma que se muestra en el ejercicio anterior.

### Ejercicio 5 (mean)

Tanto este ejercicio como el siguiente son sencillos una vez se han realizado los anteriores con lo que sólo se adjunta la salida obtenida por cada uno de los procesos Map-Reduce.

**Salida:**
```bash
Mean	-1.282261707288373
```

### Ejercicio 6 (meanAll)

**Salida:**
```bash
Mean1	0.052127765909391624
Mean2	-2.188240380935686
Mean3	-1.408876789776933
Mean4	-1.7528724942777865
Mean5	-1.282261707288373
Mean6	-2.293434905140485
Mean7	-1.5875789403216172
Mean8	-1.7390052924221087
Mean9	-1.6989002790625127
Mean0	0.25496195991785753
```

### Ejercicio 7 (balance)

Para este ejercicio simplemente lo que hacemos enviar desde el *Mapper* la clase de cada uno de las instancias del *dataset* y luego en el Reducer, considerando la clase 0 como la mayoritaria calculamos la proporción entre las clases. Como vemos obtenemos un ratio mucho mayor que 1.5 con lo que efectivamente se trata de un conjunto desbalanceado.

**Salida:**
```bash
Balance	58.582560602010815
```
### Ejercicio 8 (pearson)

Para realizar este ejercicio se ha optado por la solución que se propone en el tutorial de la práctica, así es el *Mapper* el que le pasa al *Reducer* los datos de las dos columnas, sus cuadrados y el producto de ambos y el *Reducer* se encarga de calcular las medias, la covarianza y todo lo necesario para obtener el coeficiente de correlación con los datos que le llegan. Esto lo hacemos para cada pareja de variables distintas, sin considerar la variable de clase.

Para pasar los datos al *Reducer* lo que hacemos es enviar un array (**ArrayWritable**) con todos los valores calculados en el *Mapper*, para ello se ha tenido que definir una nueva clase, **DoubleArrayWritable** que extiende a la clase **ArrayWritable** y se ha configurado el proceso en la clase principal para establecer esta clase como la de la salida del *Mapper*, además de modificar adecuadamente las clases *Mapper* y *Reducer* para que envían y reciban, respectivamente, un objeto de esta clase como valor asociado a una clave determinada.

En un principio se probó con usar un *ArrayWritable* directamente como objeto de envío pero nos daba un error, que podemos ver en los enlaces consultados, con lo que se tuvo que implementar la clase que hemos comentado. Lo que se observa es un tiempo de ejecución muy elevado (el tiempo de CPU que nos da la salida es de aproximadamente 1261550ms), quizás sea por el hecho de tener que crear para cada instancia un vector de este tipo.

**Salida:**
```bash
C0C5	0.12916572716221061
C1C4	0.058856701851937004
C2C3	-0.01726247486762999
C0C6	0.19252517591986465
C1C5	0.01465997762684827
C2C4	0.018191261366109063
C0C7	0.17921266563667684
C1C6	-0.03183255331939993
C2C5	0.024182999250758484
C3C4	0.015754379166559307
C0C8	0.06624560108156625
C1C7	-1.750366629282763E-5
C2C6	0.041153841377462724
C3C5	0.016128930425374947
C0C9	0.1382708996706929
C1C8	0.015894103474884715
C2C7	0.03814283037771738
C3C6	0.025952003813569456
C4C5	0.07125079800784533
C1C9	-0.016730623445467097
C2C8	0.025077384911599235
C3C7	0.01879122854336587
C4C6	0.018264386288745375
C2C9	0.027549270387458427
C3C8	0.016130402799924542
C4C7	0.01984291578033614
C5C6	0.03200113594875155
C3C9	0.01817123896585364
C4C8	0.01224584385595619
C5C7	0.03297998768398484
C4C9	0.014041854998880898
C5C8	0.015183324110128226
C6C7	0.11488805268078417
C5C9	0.023068393377281653
C6C8	0.07783431570283235
C6C9	0.1071360896407867
C7C8	-0.3292179447994215
C7C9	0.08936167755929571
C0C1	-0.13589916866456536
C8C9	0.1084960047958963
C0C2	0.09143593109964959
C0C3	0.07005931837575843
C1C2	-0.003036453950368947
C0C4	0.047429178238794244
C1C3	0.009438349437531437
```
## Ejercicios Adicionales

### Comparando tiempos

Lo que se ha hecho ha sido ejecutar el código que calculaba el mínimo y el máximo de la columna 5 simultáneamente sobre un conjunto que, como vimos en clase, es más pequeño que el empleado originalmente. A continuación se muestra la información del proceso que nos ofrece el servidor donde podemos observar que, como era de esperar, el proceso completo tarda más sobre el conjunto original, más grande, que sobre el nuevo. Ahora bien la información que nos ofrece el servidor nos permite realizar un análisis más profundo. Y es el *Mapper* el que presenta una mayor diferencia de tiempo entre los dos ejemplos, esto puede deberse a que el *Mapper* ha de obtener parte de los datos desde otra máquina (de ahí que tengamos en la información de salida **Rack-local map tasks=1**), y aunque en ambos casos sucede lo mismo el número de datos a tranferir de una máquina a otra sea probablemente mayor en el conjunto original.

```bash
17/05/22 08:59:49 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=2113943
		FILE: Number of bytes written=6536407
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=377165903
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=57
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=32
	Job Counters
		Launched map tasks=3
		Launched reduce tasks=16
		Data-local map tasks=2
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=72905
		Total time spent by all reduces in occupied slots (ms)=1805062
		Total time spent by all map tasks (ms)=10415
		Total time spent by all reduce tasks (ms)=36838
		Total vcore-seconds taken by all map tasks=10415
		Total vcore-seconds taken by all reduce tasks=36838
		Total megabyte-seconds taken by all map tasks=72905000
		Total megabyte-seconds taken by all reduce tasks=1841900000
	Map-Reduce Framework
		Map input records=527863
		Map output records=527863
		Map output bytes=5278630
		Map output materialized bytes=2115886
		Input split bytes=378
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2115886
		Reduce input records=527863
		Reduce output records=2
		Spilled Records=1055726
		Shuffled Maps =48
		Failed Shuffles=0
		Merged Map outputs=48
		GC time elapsed (ms)=385
		CPU time spent (ms)=25720
		Physical memory (bytes) snapshot=8154136576
		Virtual memory (bytes) snapshot=991322243072
		Total committed heap usage (bytes)=20083376128
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=377165525
	File Output Format Counters
		Bytes Written=45
```
### Parametrizando el cálculo del máximo y el mínimo (minmaxParam)

Para realizar la parametrización lo único que necesitamos es, en la clase principal del proceso, con el método `set` de la clase *JobConf*, agregar un nuevo campo con el nombre que queramos y un valor, que ha de ser un *String*, con el nuevo parámetro que le pasamos en la llamada al programa (*args[2]*). Luego en el *Mapper* definiremos la función **configure** donde recuperamos este campo con el método `get` de la clase *JobConf* para emplearlo de modo que se pasen al *Reducer* los datos de la columna deseada.

## Enlaces consultados

* [Solución al fallo que me daba al usar directamente un ArrayWritable.](http://stackoverflow.com/questions/24274668/iterate-through-arraywritable-nosuchmethodexception)
* [Cómo declarar una extensión de ArrayWritable.](https://github.com/cpieloth/GPGPU-on-Hadoop/blob/master/ocl_job_prototype/src/vecAdd/IntArrayWritable.java)
* [Cómo pasar parámetros al Mapper.](http://www.thecloudavenue.com/2011/11/passing-parameters-to-mappers-and.html)
* [Rack-local tasks vs. Data-local tasks.](https://stackoverflow.com/questions/12769376/what-is-the-difference-between-rack-local-map-tasks-and-data-local-map-tasks)
